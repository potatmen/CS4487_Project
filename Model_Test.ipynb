{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from Dataset import Dataset\n",
    "from models import Models\n",
    "from predictor import Predictor\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Models(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_choice = 'resnet50'  \n",
    "num_classes = 2  \n",
    "dropout = 0  \n",
    "model = Models(model_choice, num_out_classes=num_classes, dropout=dropout)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test dataset loading...\n",
      "Testing dataset loaded!\n",
      "Starting train dataset loading...\n",
      "Training dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "pred = Predictor(model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8167380094528198, 23.707250595092773, 1.4308995008468628, 0.7292236089706421, 0.8996493816375732, 5.170506954193115, 0.7072849273681641, 1.8967164754867554, 0.726625382900238, 0.8129971623420715, 0.9504602551460266, 0.9955135583877563, 0.7805573344230652, 0.693845272064209, 0.6752269864082336, 0.731411874294281, 0.6438043713569641, 0.7272517085075378, 0.757809579372406, 0.7170984148979187, 0.7386630773544312, 0.6923466324806213, 0.7056921720504761, 0.7066409587860107, 0.6891254186630249, 0.698839545249939, 0.6929937601089478, 0.6913568377494812, 0.7015699744224548, 0.716869592666626, 0.70801842212677, 0.6949512362480164, 0.6939606666564941, 0.6936911940574646, 0.7088279128074646, 0.6928538680076599, 0.6957066655158997, 0.6930125951766968, 0.6888043880462646, 0.7057814598083496, 0.7306960821151733, 0.6873608231544495, 0.6999802589416504, 0.7032208442687988, 0.6940320730209351, 0.6962788701057434, 0.6980943083763123, 0.6750505566596985, 0.6717626452445984, 0.691827654838562, 0.6994737982749939, 0.7081924080848694, 0.6931333541870117, 0.7245798110961914, 0.655931830406189, 0.7074757814407349, 0.6782511472702026, 0.7135326862335205, 0.7051948308944702, 0.7151745557785034, 0.6912967562675476, 0.7022523880004883, 0.6871933341026306, 0.688987135887146, 0.6890623569488525, 0.6935489177703857, 0.6996211409568787, 0.6900948286056519, 0.6968310475349426, 0.6933746933937073, 0.6963413953781128, 0.6935635209083557, 0.6946974992752075, 0.6918743848800659, 0.6939929723739624, 0.6953220367431641, 0.6942684650421143, 0.6967113614082336, 0.6935082674026489, 0.6926641464233398, 0.6969172954559326, 0.693286120891571, 0.6958081722259521, 0.6920847296714783, 0.6969447135925293, 0.6932547688484192, 0.695594310760498, 0.6927538514137268, 0.6931672692298889, 0.6931498646736145, 0.6935582160949707, 0.6946491003036499, 0.6931822299957275, 0.692446231842041, 0.6910747289657593, 0.694958508014679, 0.6933292150497437, 0.696206271648407, 0.7020838260650635, 0.6892932057380676, 0.688885509967804, 0.6900437474250793, 0.6934051513671875, 0.6917771100997925, 0.6936681270599365, 0.6938657760620117, 0.6991285681724548, 0.6989827752113342, 0.6938060522079468, 0.6857855916023254, 0.6995847225189209, 0.691794216632843, 0.6840334534645081, 0.6917484998703003, 0.6895990371704102, 0.6986269950866699, 0.6939266324043274, 0.6863822937011719, 0.6996384859085083, 0.6940997838973999, 0.6860362887382507, 0.6913655400276184, 0.7030045390129089, 0.6941002607345581, 0.6964892148971558, 0.6937837600708008, 0.6859515309333801, 0.6954609751701355, 0.700539231300354, 0.6947426795959473, 0.6959758996963501, 0.6926011443138123, 0.6928632259368896, 0.6983944773674011, 0.6913865804672241, 0.6895156502723694, 0.6898163557052612, 0.6884567737579346, 0.6961198449134827, 0.6940822005271912, 0.6943897008895874, 0.6844516396522522, 0.6949520111083984, 0.6911854147911072, 0.6954228281974792, 0.7044284343719482, 0.6912322640419006, 0.6954143047332764, 0.6994205117225647, 0.6989896893501282, 0.691201388835907, 0.6811076402664185, 0.6978946328163147, 0.6944792866706848, 0.6974400281906128, 0.6913150548934937, 0.6940851807594299, 0.6914419531822205, 0.6962559223175049, 0.693742573261261, 0.6896828413009644, 0.6955416798591614, 0.693516731262207, 0.6980454921722412, 0.6945299506187439, 0.6884087920188904, 0.6975913643836975, 0.6961156129837036, 0.6929770708084106, 0.6929336786270142, 0.690375566482544, 0.69491046667099, 0.6896611452102661, 0.6942790746688843, 0.6733595728874207, 0.6794729232788086, 0.7079459428787231, 0.6651850938796997, 0.7369161248207092, 0.712462842464447, 0.7026835680007935, 0.7133859395980835, 0.693681538105011, 0.664344847202301, 0.7662672996520996, 0.7030912041664124, 0.6973421573638916, 0.7471775412559509, 0.6930546164512634, 0.6985702514648438, 0.6995092034339905, 0.6976839303970337, 0.6932011842727661, 0.6898689866065979, 0.6803936958312988, 0.6779057383537292, 0.7160772085189819, 0.677880048751831, 0.6911911964416504, 0.698472797870636, 0.6926957964897156, 0.6931145787239075, 0.6971414685249329, 0.6911479830741882, 0.6906217336654663, 0.6916390061378479, 0.6995335221290588, 0.702296793460846, 0.6958803534507751, 0.6919692158699036, 0.6902177333831787, 0.6898288726806641, 0.6965314149856567, 0.6848939657211304, 0.6939341425895691, 0.691426157951355, 0.6739794611930847, 0.6867368221282959, 0.6971707940101624, 0.6980598568916321, 0.7244871854782104, 0.7272266745567322, 0.7102680802345276, 0.6947736144065857, 0.6991579532623291, 0.6871203184127808, 0.6933106780052185, 0.6918967366218567, 0.6910678148269653, 0.6941458582878113, 0.6847653985023499, 0.7096794843673706, 0.6994131803512573, 0.6930925846099854, 0.6824309825897217, 0.7144877314567566, 0.7165048718452454, 0.6807717680931091, 0.6875466108322144, 0.6978829503059387, 0.7001559138298035, 0.6991984248161316, 0.6984002590179443, 0.6974288821220398, 0.7034911513328552, 0.691270649433136, 0.6930011510848999, 0.6935222744941711, 0.6934790015220642, 0.6931775808334351, 0.6943362355232239, 0.6928876638412476, 0.6931192278862, 0.6931385397911072, 0.6931080222129822, 0.6931504011154175, 0.6938539743423462, 0.6931500434875488, 0.6932010650634766, 0.6921215057373047, 0.6921625137329102, 0.6965159773826599, 0.6937527656555176, 0.6991806030273438, 0.6918980479240417, 0.6909799575805664, 0.6945574283599854, 0.6971575021743774, 0.6909242868423462, 0.6936618685722351, 0.6926031708717346, 0.6908308863639832, 0.6932532787322998, 0.689621090888977, 0.6970618367195129, 0.6916337013244629, 0.6894838213920593, 0.7047677636146545, 0.6841594576835632, 0.7045485973358154, 0.696170449256897, 0.6917005777359009, 0.6983363032341003, 0.6945289373397827, 0.6947239637374878, 0.6937251687049866, 0.6923630833625793, 0.695499837398529, 0.700954020023346, 0.687811553478241, 0.6946303248405457, 0.694760262966156, 0.6905843615531921, 0.6874262690544128, 0.6901132464408875, 0.6975048184394836, 0.6916347742080688, 0.7002759575843811, 0.6915939450263977, 0.7001162171363831, 0.693647563457489, 0.69721519947052, 0.6855131387710571, 0.6918959021568298, 0.6965677738189697, 0.6831684708595276, 0.6983484029769897, 0.7000478506088257, 0.6874158978462219, 0.6949487924575806, 0.6875619292259216, 0.6856939792633057, 0.6917640566825867, 0.6856062412261963, 0.6985366344451904, 0.6939807534217834, 0.7049217820167542, 0.6967565417289734, 0.6940173506736755, 0.6989399790763855, 0.6868718266487122, 0.6915426850318909, 0.6828185319900513, 0.6938183903694153, 0.6985717415809631, 0.7031745910644531, 0.7088623046875, 0.6988183259963989, 0.6998491883277893, 0.6888219714164734, 0.6911289095878601, 0.6926187872886658, 0.6933577656745911, 0.69337397813797, 0.6931213736534119, 0.6931532025337219, 0.6931578516960144, 0.6927490234375, 0.6943089962005615, 0.6913432478904724, 0.689507246017456, 0.6932700276374817, 0.6897396445274353, 0.6905072331428528, 0.7021822333335876, 0.693575918674469, 0.6936070322990417, 0.6975573897361755, 0.6975101232528687, 0.6991533637046814, 0.700303852558136, 0.6948466300964355, 0.694503128528595, 0.6932640075683594, 0.6912244558334351, 0.6942265033721924, 0.6935003995895386, 0.6931439638137817, 0.6931542158126831, 0.6933354139328003, 0.6940425038337708, 0.6940554976463318, 0.6924859881401062, 0.6936394572257996, 0.693547785282135, 0.6924459934234619, 0.6925919055938721, 0.6938010454177856, 0.6931689381599426, 0.6940804719924927, 0.6931770443916321, 0.6936213970184326, 0.6918715834617615, 0.6926969289779663, 0.6947930455207825, 0.6921314001083374, 0.6937281489372253, 0.691001832485199, 0.6932061314582825, 0.6946409344673157, 0.6924893260002136, 0.6947422623634338, 0.6947053670883179, 0.6945434808731079, 0.6937384605407715, 0.6918782591819763, 0.6954457759857178, 0.6935561895370483, 0.6931329369544983, 0.6932170391082764, 0.6926894783973694, 0.6936199069023132, 0.6943718791007996, 0.692876398563385, 0.6928834319114685, 0.6928635835647583, 0.694133460521698, 0.6905517578125, 0.6922786235809326, 0.6907119154930115, 0.696679413318634, 0.6922885179519653, 0.6966650485992432, 0.6968187689781189, 0.6956074237823486, 0.6911326050758362, 0.6943303346633911, 0.6932714581489563, 0.6904189586639404, 0.697117805480957, 0.6905850768089294, 0.6923688054084778, 0.695006251335144, 0.6898860931396484, 0.6967371702194214, 0.6932348012924194, 0.6947742700576782, 0.6911315321922302, 0.6938691735267639, 0.6938281059265137, 0.6914823055267334, 0.6960082650184631, 0.6941083073616028, 0.6934941411018372, 0.6925771236419678, 0.6937492489814758, 0.6931696534156799, 0.6933236122131348, 0.6934137940406799, 0.6944027543067932, 0.6931551098823547, 0.6931517124176025, 0.6940740346908569, 0.6928962469100952, 0.6928655505180359, 0.6933450698852539, 0.6930578947067261, 0.6934753656387329, 0.6931561231613159, 0.6930891871452332, 0.6933534145355225, 0.6931498646736145, 0.6930816173553467, 0.6931500434875488, 0.6927719116210938, 0.693164050579071, 0.6916787624359131, 0.6915869116783142, 0.6961105465888977, 0.6940335631370544, 0.6967599391937256, 0.6898490190505981, 0.6968363523483276, 0.6932202577590942, 0.6915968656539917, 0.6932435035705566, 0.6932215690612793, 0.6948082447052002, 0.6961963176727295, 0.6956532001495361, 0.6935974955558777, 0.692939817905426, 0.6932704448699951, 0.69292151927948, 0.6934750080108643, 0.6927002668380737, 0.6900239586830139, 0.6914843916893005, 0.6944428086280823, 0.690708577632904, 0.6996259689331055, 0.6951342821121216, 0.6901229619979858, 0.68819659948349, 0.6955388784408569, 0.6996712684631348, 0.6856235861778259, 0.6937119364738464, 0.6915929913520813, 0.6937572360038757, 0.6870455145835876, 0.6891598105430603, 0.6914648413658142, 0.6914185881614685, 0.686022162437439, 0.6885069608688354, 0.7002971172332764, 0.6943591833114624, 0.7007047533988953, 0.6881287097930908, 0.6849903464317322, 0.6880409717559814, 0.6879408359527588, 0.6843963265419006, 0.6876391768455505, 0.6874465346336365, 0.6911845207214355, 0.6912011504173279, 0.7081322073936462, 0.6742262840270996, 0.6693708300590515, 0.6912803649902344, 0.6913005113601685, 0.6660049557685852, 0.7024289965629578, 0.7201498746871948, 0.6576002240180969, 0.6858037710189819, 0.7162075042724609, 0.7100489735603333, 0.7154173254966736, 0.6859386563301086, 0.6860724687576294, 0.6862040758132935, 0.7014778852462769, 0.7010892033576965, 0.6865843534469604, 0.7092475891113281, 0.6741417646408081, 0.7036146521568298, 0.6872321367263794, 0.6796931624412537, 0.6987571716308594, 0.669039249420166, 0.6911877989768982, 0.7025447487831116, 0.7024722099304199, 0.6801473498344421, 0.6912073493003845, 0.6948608756065369, 0.6984773278236389, 0.6840462684631348, 0.6840954422950745, 0.6947836875915527, 0.7055875658988953, 0.7018004059791565, 0.6946313381195068, 0.7010483145713806, 0.70059734582901, 0.6913268566131592, 0.7022200226783752, 0.701204240322113, 0.6916472911834717, 0.690186083316803, 0.6875618100166321, 0.6949735283851624, 0.6964311003684998, 0.6933802962303162, 0.6970776319503784, 0.6912862062454224, 0.6898581385612488, 0.6950206160545349, 0.6890990734100342, 0.694197952747345, 0.6913047432899475, 0.6880179047584534, 0.698196530342102, 0.6883600950241089, 0.6974220871925354, 0.6893616914749146, 0.6920055150985718, 0.6963745355606079, 0.6876052021980286, 0.6887629628181458, 0.6970842480659485, 0.6935744881629944, 0.6954866647720337, 0.687981128692627, 0.6897277235984802, 0.6852535605430603, 0.6963406205177307, 0.6993423700332642, 0.6754236817359924, 0.6943163871765137, 0.7046549320220947, 0.7078754901885986, 0.6942898631095886, 0.7050520181655884, 0.6961976289749146, 0.70175701379776, 0.6935217976570129, 0.6934309005737305, 0.6880839467048645, 0.689640462398529, 0.6921409964561462, 0.698030412197113, 0.6911129355430603, 0.6880228519439697, 0.692218005657196, 0.6922004222869873, "
     ]
    }
   ],
   "source": [
    "pred.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
